{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AML project part1 - GP_VAE_generation_yaniv.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Reproduce GP-VAE\n",
        "## Instructions for use:\n",
        "1. Clone our GP-VAE repo (**Add link here**) to your google drive\n",
        "2. Place this notebook in your google drive\n",
        "3. Update the ROOT_PATH to the repo folder in your g drive\n",
        "4. **Only for the first time you run on a colab host**: perform initial installations and fixes:\n",
        "  * Un-Comment code cell 2\n",
        "  * Execute code cells 1, 2 \n",
        "  * Comment cell 2 back\n",
        "  * Restart the host\n",
        "5. Run the notebook\n",
        "\n",
        "**Note**: The train / test outputs (model, results) will be copied into the repository clone under 'model' folder in the end, as intended by the original writers."
      ],
      "metadata": {
        "id": "IvAhUzMhgA38"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run one time only, then comment and restart the host\n",
        "\n",
        "# !pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "onWfpZNxcXlm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WjLpdDbq8J2L",
        "outputId": "ea587c39-8137-4e93-ebfa-b57cfc2e686b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "total 92\n",
            "drwxr-xr-x 1 root root  4096 Aug 15 17:00 .\n",
            "drwxr-xr-x 1 root root  4096 Aug 15 16:56 ..\n",
            "drwxr-xr-x 4 root root  4096 Aug  3 20:20 .config\n",
            "drwx------ 2 root root  4096 Aug 15 16:58 data\n",
            "drwx------ 5 root root  4096 Aug 15 16:58 drive\n",
            "drwx------ 2 root root  4096 Aug 15 16:58 figures\n",
            "-rw------- 1 root root  8587 Aug 15 18:50 generate.py\n",
            "drwx------ 3 root root  4096 Aug 15 16:58 lib\n",
            "-rw------- 1 root root  1087 Aug 15 18:50 LICENSE\n",
            "drwxr-xr-x 3 root root  4096 Aug 15 17:49 outputs\n",
            "drwx------ 2 root root  4096 Aug 15 17:47 __pycache__\n",
            "-rw------- 1 root root  2364 Aug 15 18:50 README.md\n",
            "-rw------- 1 root root   146 Aug 15 18:50 requirements.txt\n",
            "drwxr-xr-x 1 root root  4096 Aug  3 20:21 sample_data\n",
            "-rw------- 1 root root 17967 Aug 15 18:50 train.py\n",
            "drwx------ 2 root root  4096 Aug 15 17:00 utils\n",
            "-rw------- 1 root root  2579 Aug 15 18:50 utils.py\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "from pathlib import Path\n",
        "from google.colab import drive\n",
        "\n",
        "# Google Drive linkage\n",
        "drive.mount('/content/drive')\n",
        "DRIVE_ROOT_DIR = Path('/content/drive/MyDrive/colab_data/aml_project/gp_vae_for_data_generation')\n",
        "DRIVE_DATA_DIR = Path('/content/drive/MyDrive/colab_data/aml_project/data/hmnist_full.npz')\n",
        "\n",
        "# copy code to colab host\n",
        "!cp -R $DRIVE_ROOT_DIR/* .\n",
        "!ls -la $ROOT_DIR"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train model"
      ],
      "metadata": {
        "id": "PrXv5V5EI7IH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create output folders for this run\n",
        "\n",
        "# Relative paths - correct both for drive and for local (Colab) VM\n",
        "datetime = time.strftime(\"%Y%m%d-%H%M%S\")\n",
        "OUTPUTS_DIR = Path(f'outputs/{datetime}')\n",
        "DRIVE_OUTPUTS_DIR = DRIVE_ROOT_DIR / OUTPUTS_DIR\n",
        "\n",
        "# Create output folders on local (Colab) VM\n",
        "Path(OUTPUTS_DIR).mkdir(parents=True, exist_ok=True)\n",
        "print(f'OUTPUTS_DIR = {OUTPUTS_DIR}, exists = {Path.exists(OUTPUTS_DIR)}')\n",
        "\n",
        "Path(DRIVE_OUTPUTS_DIR).mkdir(parents=True, exist_ok=True)\n",
        "print(f'DRIVE_OUTPUTS_DIR = {DRIVE_OUTPUTS_DIR}, exists = {Path.exists(DRIVE_OUTPUTS_DIR)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nx0cg57qnIH9",
        "outputId": "f8782f6b-813a-47ff-8962-abb830b05eb2"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OUTPUTS_DIR = outputs/20220815-174959, exists = True\n",
            "DRIVE_OUTPUTS_DIR = /content/drive/MyDrive/colab_data/aml_project/gp_vae_for_data_generation/outputs/20220815-174959, exists = True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #Train on limited dataset\n",
        "SAMPLES_PER_DIGIT = 500\n",
        "NUM_EPOCHS = 25\n",
        "WHITE_FLIP_RATIO = 0.6\n",
        "BLACK_FLIP_RATIO = 0.8\n",
        "\n",
        "!python train.py --model_type gp-vae --seed 123 --data_type hmnist --banded_covar --latent_dim 256 --encoder_sizes=256,256 --decoder_sizes=256,256,256 --window_size 3 --sigma 1 --length_scale 2 --beta 0.8 --num_epochs $NUM_EPOCHS --train_class_number $SAMPLES_PER_DIGIT --data_dir $DRIVE_DATA_DIR --base_dir $OUTPUTS_DIR --black_flip_ratio $BLACK_FLIP_RATIO --white_flip_ratio $WHITE_FLIP_RATIO"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VegyQpEW9ZQT",
        "outputId": "0843df4c-8251-4b75-81ee-af2012d0b44e"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed: {FLAGS.seed}\n",
            "Outputs will be saved to:  outputs/20220815-174959/model\n",
            "tcmalloc: large alloc 3763200000 bytes == 0x67b6000 @  0x7f95965251e7 0x7f9592fbacf1 0x7f959301f7c8 0x7f9592fbe4f1 0x5947d6 0x548cc1 0x5127f1 0x549576 0x593fce 0x548ae9 0x5127f1 0x4bc98a 0x533274 0x4d3969 0x512147 0x549e0e 0x593fce 0x5118f8 0x593dd7 0x5118f8 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x604173 0x5f5506 0x5f8c6c 0x5f9206 0x64faf2 0x64fc4e\n",
            "tcmalloc: large alloc 1881604096 bytes == 0xe6cd4000 @  0x7f95965251e7 0x7f9592fbacf1 0x7f95930225d0 0x7f95930b2ab2 0x59b1b0 0x515655 0x549e0e 0x593fce 0x5118f8 0x593dd7 0x5118f8 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x604173 0x5f5506 0x5f8c6c 0x5f9206 0x64faf2 0x64fc4e 0x7f9596122c87 0x5b621a\n",
            "Loading data...Done!\n",
            "10000\n",
            "2022-08-15 17:50:30.035997: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2022-08-15 17:50:30.136446: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-08-15 17:50:30.137179: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2022-08-15 17:50:30.151692: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2022-08-15 17:50:30.449483: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2022-08-15 17:50:30.580858: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2022-08-15 17:50:30.618441: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2022-08-15 17:50:30.865926: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2022-08-15 17:50:30.986742: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2022-08-15 17:50:31.383835: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2022-08-15 17:50:31.384064: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-08-15 17:50:31.384773: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-08-15 17:50:31.385295: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2022-08-15 17:50:31.385729: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "2022-08-15 17:50:31.436374: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199995000 Hz\n",
            "2022-08-15 17:50:31.442688: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2410a00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2022-08-15 17:50:31.442726: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2022-08-15 17:50:31.700434: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-08-15 17:50:31.702352: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2410840 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2022-08-15 17:50:31.702385: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2022-08-15 17:50:31.702605: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-08-15 17:50:31.703150: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2022-08-15 17:50:31.703228: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2022-08-15 17:50:31.703253: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2022-08-15 17:50:31.703273: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2022-08-15 17:50:31.703291: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2022-08-15 17:50:31.703313: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2022-08-15 17:50:31.703332: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2022-08-15 17:50:31.703352: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2022-08-15 17:50:31.703426: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-08-15 17:50:31.703973: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-08-15 17:50:31.704480: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2022-08-15 17:50:31.709199: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2022-08-15 17:50:31.710688: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2022-08-15 17:50:31.710733: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2022-08-15 17:50:31.710745: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2022-08-15 17:50:31.717865: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-08-15 17:50:31.718519: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-08-15 17:50:31.721670: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2022-08-15 17:50:31.721725: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14257 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "W0815 17:50:35.754313 140280453224320 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/data/util/random_seed.py:58: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "2022-08-15 17:50:35.771412: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 313600000 exceeds 10% of system memory.\n",
            "2022-08-15 17:50:35.921854: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 627200000 exceeds 10% of system memory.\n",
            "Using CNN preprocessor\n",
            "2022-08-15 17:50:36.177616: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-08-15 17:50:36.178217: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2022-08-15 17:50:36.178307: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2022-08-15 17:50:36.178330: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2022-08-15 17:50:36.178352: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2022-08-15 17:50:36.178371: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2022-08-15 17:50:36.178390: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2022-08-15 17:50:36.178409: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2022-08-15 17:50:36.178428: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2022-08-15 17:50:36.178513: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-08-15 17:50:36.179055: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-08-15 17:50:36.179552: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2022-08-15 17:50:36.179593: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2022-08-15 17:50:36.179606: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2022-08-15 17:50:36.179615: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2022-08-15 17:50:36.179712: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-08-15 17:50:36.180259: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-08-15 17:50:36.180754: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/device:GPU:0 with 14257 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "GPU support:  True\n",
            "Training...\n",
            "2022-08-15 17:50:36.263830: I tensorflow/core/kernels/cuda_solvers.cc:159] Creating CudaSolver handles for stream 0x19911b20\n",
            "2022-08-15 17:50:36.263929: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2022-08-15 17:50:37.481623: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2022-08-15 17:50:38.169716: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2022-08-15 17:50:42.735288: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              multiple                  602368    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                multiple                  65792     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              multiple                  197376    \n",
            "=================================================================\n",
            "Total params: 865,536\n",
            "Trainable params: 865,536\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Encoder:  None\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_2 (Dense)              multiple                  65792     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              multiple                  65792     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              multiple                  65792     \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              multiple                  201488    \n",
            "=================================================================\n",
            "Total params: 398,864\n",
            "Trainable params: 398,864\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Decoder:  None\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              multiple                  2560      \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            multiple                  2305      \n",
            "=================================================================\n",
            "Total params: 4,865\n",
            "Trainable params: 4,865\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Preprocessor:  None\n",
            "W0815 17:50:43.024775 140280453224320 lazy_loader.py:50] \n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "2022-08-15 17:50:44.223414: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 313600000 exceeds 10% of system memory.\n",
            "2022-08-15 17:50:44.426677: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 627200000 exceeds 10% of system memory.\n",
            "================================================\n",
            "Learning rate: 0.001 | Global gradient norm: 436.20\n",
            "Step 0) Time = 2.761625\n",
            "Train loss = 6248.395 | NLL = 1203.807 | KL = 6305.734\n",
            "Validation loss = 6245.609 | NLL = 1200.786 | KL = 6306.029\n",
            "================================================\n",
            "Learning rate: 0.001 | Global gradient norm: 589.95\n",
            "Step 156) Time = 95.917577\n",
            "Train loss = 1648.681 | NLL = 628.546 | KL = 1275.169\n",
            "Validation loss = 1603.192 | NLL = 582.366 | KL = 1276.032\n",
            "================================================\n",
            "Learning rate: 0.001 | Global gradient norm: 557.39\n",
            "Step 312) Time = 97.154865\n",
            "Train loss = 1501.433 | NLL = 475.446 | KL = 1282.484\n",
            "Validation loss = 1486.408 | NLL = 459.779 | KL = 1283.287\n",
            "================================================\n",
            "Learning rate: 0.001 | Global gradient norm: 359.63\n",
            "Step 468) Time = 97.795921\n",
            "Train loss = 1448.190 | NLL = 417.543 | KL = 1288.309\n",
            "Validation loss = 1425.369 | NLL = 394.291 | KL = 1288.848\n",
            "================================================\n",
            "Learning rate: 0.001 | Global gradient norm: 1748.67\n",
            "Step 624) Time = 97.613011\n",
            "Train loss = 1402.431 | NLL = 363.935 | KL = 1298.120\n",
            "Validation loss = 1404.367 | NLL = 364.899 | KL = 1299.336\n",
            "================================================\n",
            "Learning rate: 0.001 | Global gradient norm: 1475.06\n",
            "Step 780) Time = 96.830862\n",
            "Train loss = 1375.582 | NLL = 335.930 | KL = 1299.564\n",
            "Validation loss = 1363.448 | NLL = 323.878 | KL = 1299.462\n",
            "================================================\n",
            "Learning rate: 0.001 | Global gradient norm: 1963.65\n",
            "Step 936) Time = 97.228408\n",
            "Train loss = 1357.232 | NLL = 313.860 | KL = 1304.214\n",
            "Validation loss = 1354.201 | NLL = 312.308 | KL = 1302.367\n",
            "================================================\n",
            "Learning rate: 0.001 | Global gradient norm: 266.03\n",
            "Step 1092) Time = 96.728111\n",
            "Train loss = 1351.113 | NLL = 305.703 | KL = 1306.762\n",
            "Validation loss = 1343.015 | NLL = 298.826 | KL = 1305.236\n",
            "================================================\n",
            "Learning rate: 0.001 | Global gradient norm: 388.73\n",
            "Step 1248) Time = 96.788676\n",
            "Train loss = 1322.140 | NLL = 275.118 | KL = 1308.777\n",
            "Validation loss = 1346.906 | NLL = 301.776 | KL = 1306.413\n",
            "================================================\n",
            "Learning rate: 0.001 | Global gradient norm: 614.00\n",
            "Step 1404) Time = 97.204870\n",
            "Train loss = 1318.071 | NLL = 270.126 | KL = 1309.931\n",
            "Validation loss = 1327.851 | NLL = 281.785 | KL = 1307.582\n",
            "================================================\n",
            "Learning rate: 0.001 | Global gradient norm: 1432.86\n",
            "Step 1560) Time = 96.419957\n",
            "Train loss = 1305.871 | NLL = 255.811 | KL = 1312.575\n",
            "Validation loss = 1297.340 | NLL = 249.515 | KL = 1309.782\n",
            "================================================\n",
            "Learning rate: 0.001 | Global gradient norm: 3906.19\n",
            "Step 1716) Time = 97.062891\n",
            "Train loss = 1297.364 | NLL = 247.435 | KL = 1312.410\n",
            "Validation loss = 1303.848 | NLL = 253.277 | KL = 1313.214\n",
            "================================================\n",
            "Learning rate: 0.001 | Global gradient norm: 2761.88\n",
            "Step 1872) Time = 96.714527\n",
            "Train loss = 1311.162 | NLL = 259.749 | KL = 1314.267\n",
            "Validation loss = 1299.095 | NLL = 248.596 | KL = 1313.125\n",
            "================================================\n",
            "Learning rate: 0.001 | Global gradient norm: 1781.26\n",
            "Step 2028) Time = 96.521816\n",
            "Train loss = 1289.943 | NLL = 236.623 | KL = 1316.651\n",
            "Validation loss = 1306.206 | NLL = 254.148 | KL = 1315.073\n",
            "================================================\n",
            "Learning rate: 0.001 | Global gradient norm: 2341.63\n",
            "Step 2184) Time = 95.994638\n",
            "Train loss = 1276.748 | NLL = 223.806 | KL = 1316.177\n",
            "Validation loss = 1292.186 | NLL = 240.387 | KL = 1314.748\n",
            "================================================\n",
            "Learning rate: 0.001 | Global gradient norm: 263.08\n",
            "Step 2340) Time = 96.144797\n",
            "Train loss = 1291.837 | NLL = 237.712 | KL = 1317.656\n",
            "Validation loss = 1274.706 | NLL = 224.022 | KL = 1313.355\n",
            "================================================\n",
            "Learning rate: 0.001 | Global gradient norm: 977.72\n",
            "Step 2496) Time = 95.948632\n",
            "Train loss = 1277.567 | NLL = 223.652 | KL = 1317.394\n",
            "Validation loss = 1285.016 | NLL = 232.441 | KL = 1315.719\n",
            "================================================\n",
            "Learning rate: 0.001 | Global gradient norm: 677.01\n",
            "Step 2652) Time = 96.463633\n",
            "Train loss = 1275.334 | NLL = 219.402 | KL = 1319.916\n",
            "Validation loss = 1278.518 | NLL = 224.943 | KL = 1316.968\n",
            "================================================\n",
            "Learning rate: 0.001 | Global gradient norm: 3532.60\n",
            "Step 2808) Time = 96.048985\n",
            "Train loss = 1295.238 | NLL = 236.730 | KL = 1323.135\n",
            "Validation loss = 1280.664 | NLL = 227.113 | KL = 1316.939\n",
            "================================================\n",
            "Learning rate: 0.001 | Global gradient norm: 537.20\n",
            "Step 2964) Time = 95.938530\n",
            "Train loss = 1290.434 | NLL = 235.767 | KL = 1318.333\n",
            "Validation loss = 1283.702 | NLL = 231.546 | KL = 1315.195\n",
            "================================================\n",
            "Learning rate: 0.001 | Global gradient norm: 1113.27\n",
            "Step 3120) Time = 95.724137\n",
            "Train loss = 1269.955 | NLL = 216.205 | KL = 1317.188\n",
            "Validation loss = 1273.484 | NLL = 221.597 | KL = 1314.859\n",
            "================================================\n",
            "Learning rate: 0.001 | Global gradient norm: 858.56\n",
            "Step 3276) Time = 95.543612\n",
            "Train loss = 1281.938 | NLL = 221.009 | KL = 1326.162\n",
            "Validation loss = 1280.556 | NLL = 225.180 | KL = 1319.221\n",
            "================================================\n",
            "Learning rate: 0.001 | Global gradient norm: 1567.76\n",
            "Step 3432) Time = 96.725885\n",
            "Train loss = 1280.174 | NLL = 221.713 | KL = 1323.076\n",
            "Validation loss = 1291.894 | NLL = 237.144 | KL = 1318.438\n",
            "================================================\n",
            "Learning rate: 0.001 | Global gradient norm: 383.49\n",
            "Step 3588) Time = 96.736243\n",
            "Train loss = 1265.266 | NLL = 205.618 | KL = 1324.559\n",
            "Validation loss = 1272.931 | NLL = 215.333 | KL = 1321.997\n",
            "================================================\n",
            "Learning rate: 0.001 | Global gradient norm: 451.29\n",
            "Step 3744) Time = 96.156932\n",
            "Train loss = 1258.905 | NLL = 200.706 | KL = 1322.748\n",
            "Validation loss = 1262.125 | NLL = 206.131 | KL = 1319.992\n",
            "================================================\n",
            "Learning rate: 0.001 | Global gradient norm: 217.90\n",
            "Step 3900) Time = 96.293008\n",
            "Train loss = 1254.791 | NLL = 197.892 | KL = 1321.124\n",
            "Validation loss = 1268.151 | NLL = 210.051 | KL = 1322.626\n",
            "Evaluation...\n",
            "NLL miss: 0.1083\n",
            "MSE miss: 0.0394\n",
            "Traceback (most recent call last):\n",
            "  File \"train.py\", line 375, in <module>\n",
            "    app.run(main)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 300, in run\n",
            "    _run_main(main, args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 251, in _run_main\n",
            "    sys.exit(main(argv))\n",
            "  File \"train.py\", line 321, in main\n",
            "    auprc = average_precision_score(np.eye(num_classes)[y_val[val_split:]], probs)\n",
            "IndexError: index 19 is out of bounds for axis 0 with size 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy trained models back to drive\n",
        "!cp -R $OUTPUTS_DIR/* $DRIVE_OUTPUTS_DIR\n",
        "print(f'DRIVE_OUTPUTS_DIR = {DRIVE_OUTPUTS_DIR}')\n",
        "!ls -la $DRIVE_OUTPUTS_DIR\n"
      ],
      "metadata": {
        "id": "Se5Ggzi2Q4NS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "088b20a5-0f3f-489d-8876-44c28706ffad"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DRIVE_OUTPUTS_DIR = /content/drive/MyDrive/colab_data/aml_project/gp_vae_for_data_generation/outputs/20220815-174959\n",
            "total 306259\n",
            "-rw------- 1 root root 313600128 Aug 15 18:51 base_data.npy\n",
            "drwx------ 2 root root      4096 Aug 15 18:51 generated_data\n",
            "drwx------ 2 root root      4096 Aug 15 18:51 model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate new samples based on the dataset used in train and the model"
      ],
      "metadata": {
        "id": "ajfeYCM0I_zL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Train on limited dataset\n",
        "WHITE_FLIP_RATIO = 0.6\n",
        "BLACK_FLIP_RATIO = 0.8\n",
        "\n",
        "!python generate.py --model_type gp-vae --data_type hmnist --seed 123 --testing --banded_covar --latent_dim 256 --encoder_sizes=256,256 --decoder_sizes=256,256,256 --window_size 3 --sigma 1 --length_scale 2 --beta 0.8 --num_epochs 20 --base_dir $OUTPUTS_DIR --black_flip_ratio $BLACK_FLIP_RATIO --white_flip_ratio $WHITE_FLIP_RATIO"
      ],
      "metadata": {
        "id": "c6bvmGNwIxGW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "937dddfe-26f5-429f-8687-51c1f0b06d2e"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing:  True \t Seed: 123\n",
            "GENERATED_DATA_PATH = outputs/20220815-174959/generated_data, exists = True\n",
            "2022-08-15 18:51:47.571064: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2022-08-15 18:51:47.652686: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-08-15 18:51:47.653286: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2022-08-15 18:51:47.665296: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2022-08-15 18:51:47.857247: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2022-08-15 18:51:47.939936: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2022-08-15 18:51:47.961974: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2022-08-15 18:51:48.204243: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2022-08-15 18:51:48.340670: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2022-08-15 18:51:48.795864: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2022-08-15 18:51:48.796141: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-08-15 18:51:48.796862: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-08-15 18:51:48.797556: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2022-08-15 18:51:48.798016: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "2022-08-15 18:51:48.855069: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199995000 Hz\n",
            "2022-08-15 18:51:48.870982: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x18f6a00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2022-08-15 18:51:48.871047: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2022-08-15 18:51:49.196888: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-08-15 18:51:49.200594: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x18f6840 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2022-08-15 18:51:49.200636: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2022-08-15 18:51:49.200876: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-08-15 18:51:49.201519: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2022-08-15 18:51:49.201598: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2022-08-15 18:51:49.201620: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2022-08-15 18:51:49.201636: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2022-08-15 18:51:49.201658: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2022-08-15 18:51:49.201678: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2022-08-15 18:51:49.201696: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2022-08-15 18:51:49.201715: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2022-08-15 18:51:49.201794: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-08-15 18:51:49.202412: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-08-15 18:51:49.202931: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2022-08-15 18:51:49.206922: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2022-08-15 18:51:49.208214: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2022-08-15 18:51:49.208244: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2022-08-15 18:51:49.208255: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2022-08-15 18:51:49.214512: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-08-15 18:51:49.215116: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-08-15 18:51:49.217924: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2022-08-15 18:51:49.218010: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14257 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "2022-08-15 18:51:54.030879: I tensorflow/core/kernels/cuda_solvers.cc:159] Creating CudaSolver handles for stream 0x50ecdac8\n",
            "2022-08-15 18:51:54.031004: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2022-08-15 18:51:54.647443: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2022-08-15 18:51:54.950506: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2022-08-15 18:51:56.408886: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "W0815 18:51:56.501265 140571261642624 deprecation.py:323] From /content/lib/models.py:119: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              multiple                  602368    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                multiple                  65792     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              multiple                  197376    \n",
            "=================================================================\n",
            "Total params: 865,536\n",
            "Trainable params: 865,536\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Encoder:  None\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_2 (Dense)              multiple                  65792     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              multiple                  65792     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              multiple                  65792     \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              multiple                  201488    \n",
            "=================================================================\n",
            "Total params: 398,864\n",
            "Trainable params: 398,864\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Decoder:  None\n",
            "Generating...\n",
            "Generation finished.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy trained models back to drive\n",
        "!cp -R $OUTPUTS_DIR/generated_data $DRIVE_OUTPUTS_DIR\n",
        "print(f'DRIVE_OUTPUTS_DIR = {DRIVE_OUTPUTS_DIR}')\n",
        "!ls -la $DRIVE_OUTPUTS_DIR/generated_data\n",
        "\n"
      ],
      "metadata": {
        "id": "7m2_pd0INqMT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d4cd583-c9f3-44d5-dbbe-98d80d5500ff"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DRIVE_OUTPUTS_DIR = /content/drive/MyDrive/colab_data/aml_project/gp_vae_for_data_generation/outputs/20220815-174959\n",
            "total 713390\n",
            "-rw------- 1 root root    909278 Aug 15 18:52 hmnist_30.png\n",
            "-rw------- 1 root root 313600128 Aug 15 18:52 imputed_no_gt.npy\n",
            "-rw------- 1 root root 313600128 Aug 15 18:52 imputed.npy\n",
            "-rw------- 1 root root 102400128 Aug 15 18:52 z_mean.npy\n"
          ]
        }
      ]
    }
  ]
}