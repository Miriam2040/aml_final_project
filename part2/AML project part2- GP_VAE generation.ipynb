{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GP_VAE.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "background_execution": "on"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WjLpdDbq8J2L",
        "outputId": "64c0d6a2-0a08-4bcb-85bd-1470e4d5874d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "output_dir = /content/drive/MyDrive/AML_Project/GP-VAE/output, exists = True\n",
            "total 53\n",
            "drwx------ 2 root root  4096 Jul 14 11:18 data\n",
            "drwx------ 2 root root  4096 Jul 14 11:18 figures\n",
            "drwx------ 2 root root  4096 Jul 14 11:18 .git\n",
            "-rw------- 1 root root  1198 Jul 14 11:18 .gitignore\n",
            "drwx------ 2 root root  4096 Jul 14 11:18 lib\n",
            "-rw------- 1 root root  1066 Jul 14 11:18 LICENSE\n",
            "drwx------ 2 root root  4096 Jul 14 11:18 models\n",
            "drwx------ 2 root root  4096 Jul 14 11:25 output\n",
            "-rw------- 1 root root  2324 Jul 14 11:18 README.md\n",
            "-rw------- 1 root root   138 Jul 14 11:18 requirements.txt\n",
            "-rw------- 1 root root 23429 Jul 14 11:18 train.py\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "ROOT_DIR = Path('/content/drive/MyDrive/AML_Project/GP-VAE')\n",
        "OUTPUT_DIR = ROOT_DIR / Path('output')\n",
        "\n",
        "Path(OUTPUT_DIR).mkdir(parents=True, exist_ok=True)\n",
        "print(f'output_dir = {OUTPUT_DIR}, exists = {Path.exists(OUTPUT_DIR)}')\n",
        "\n",
        "!ls -la $ROOT_DIR"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Run this cell once for a new host, then comment this cell, restart the host, and rerun all\n",
        "# #---------------------------------------------------------------------------------\n",
        "\n",
        "# # copy github repo to colab host\n",
        "!cp -R $ROOT_DIR/* .\n",
        "\n",
        "# # Update data download scripts\n",
        "!sudo apt-get install dos2unix\n",
        "!dos2unix data/*.sh\n",
        "!chmod +x data/*.sh\n",
        "!ls -la data\n",
        "\n",
        "# # reinstall old packages for old code\n",
        "!pip install -r requirements.txt\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Sxfzj6mC_-78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6e68d1de-3005-473f-ae3c-73a124093581"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "The following NEW packages will be installed:\n",
            "  dos2unix\n",
            "0 upgraded, 1 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 351 kB of archives.\n",
            "After this operation, 1,267 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 dos2unix amd64 7.3.4-3 [351 kB]\n",
            "Fetched 351 kB in 0s (4,008 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package dos2unix.\n",
            "(Reading database ... 155673 files and directories currently installed.)\n",
            "Preparing to unpack .../dos2unix_7.3.4-3_amd64.deb ...\n",
            "Unpacking dos2unix (7.3.4-3) ...\n",
            "Setting up dos2unix (7.3.4-3) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "dos2unix: converting file data/load_hmnist.sh to Unix format...\n",
            "dos2unix: converting file data/load_physionet.sh to Unix format...\n",
            "dos2unix: converting file data/load_sprites.sh to Unix format...\n",
            "total 20\n",
            "drwx------ 2 root root 4096 Jul 31 10:32 .\n",
            "drwxr-xr-x 1 root root 4096 Jul 31 10:32 ..\n",
            "-rwx--x--x 1 root root  932 Jul 31 10:32 load_hmnist.sh\n",
            "-rwx--x--x 1 root root  143 Jul 31 10:32 load_physionet.sh\n",
            "-rwx--x--x 1 root root  137 Jul 31 10:32 load_sprites.sh\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting absl-py==0.7.0\n",
            "  Downloading absl-py-0.7.0.tar.gz (96 kB)\n",
            "\u001b[K     |████████████████████████████████| 96 kB 4.4 MB/s \n",
            "\u001b[?25hCollecting numpy==1.16.4\n",
            "  Downloading numpy-1.16.4-cp37-cp37m-manylinux1_x86_64.whl (17.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 17.3 MB 88.0 MB/s \n",
            "\u001b[?25hCollecting scipy==1.2.0\n",
            "  Downloading scipy-1.2.0-cp37-cp37m-manylinux1_x86_64.whl (26.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 26.6 MB 1.1 MB/s \n",
            "\u001b[?25hCollecting tensorflow==1.15.0\n",
            "  Downloading tensorflow-1.15.0-cp37-cp37m-manylinux2010_x86_64.whl (412.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 412.3 MB 24 kB/s \n",
            "\u001b[?25hCollecting tensorflow-gpu==1.15.0\n",
            "  Downloading tensorflow_gpu-1.15.0-cp37-cp37m-manylinux2010_x86_64.whl (411.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 411.5 MB 6.3 kB/s \n",
            "\u001b[?25hCollecting tensorflow_probability==0.7.0\n",
            "  Downloading tensorflow_probability-0.7.0-py2.py3-none-any.whl (981 kB)\n",
            "\u001b[K     |████████████████████████████████| 981 kB 70.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (3.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 8)) (1.0.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py==0.7.0->-r requirements.txt (line 1)) (1.15.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0->-r requirements.txt (line 4)) (1.47.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0->-r requirements.txt (line 4)) (0.37.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0->-r requirements.txt (line 4)) (3.3.0)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading gast-0.2.2.tar.gz (10 kB)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0->-r requirements.txt (line 4)) (3.17.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0->-r requirements.txt (line 4)) (0.2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0->-r requirements.txt (line 4)) (1.1.0)\n",
            "Collecting keras-applications>=1.0.8\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 7.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0->-r requirements.txt (line 4)) (0.8.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0->-r requirements.txt (line 4)) (1.14.1)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "  Downloading tensorboard-1.15.0-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 71.0 MB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator==1.15.1\n",
            "  Downloading tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503 kB)\n",
            "\u001b[K     |████████████████████████████████| 503 kB 88.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0->-r requirements.txt (line 4)) (1.1.2)\n",
            "Requirement already satisfied: cloudpickle>=0.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow_probability==0.7.0->-r requirements.txt (line 6)) (1.3.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from tensorflow_probability==0.7.0->-r requirements.txt (line 6)) (4.4.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15.0->-r requirements.txt (line 4)) (3.1.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0->-r requirements.txt (line 4)) (3.4.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0->-r requirements.txt (line 4)) (57.4.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0->-r requirements.txt (line 4)) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0->-r requirements.txt (line 4)) (4.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0->-r requirements.txt (line 4)) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0->-r requirements.txt (line 4)) (3.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 7)) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 7)) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 7)) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 7)) (1.4.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->-r requirements.txt (line 8)) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->-r requirements.txt (line 8)) (1.1.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->tensorflow==1.15.0->-r requirements.txt (line 4)) (1.5.2)\n",
            "Building wheels for collected packages: absl-py, gast\n",
            "  Building wheel for absl-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for absl-py: filename=absl_py-0.7.0-py3-none-any.whl size=113528 sha256=12e5e288fcb9eadd86f742f6428c1415fb6cab1b990d2c0436ba5b5e72ab0cf7\n",
            "  Stored in directory: /root/.cache/pip/wheels/7a/3a/ce/7f67462856699d5adaf0bab747964f5db6a138473374d46c4d\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7554 sha256=279e5407bbd6b88ffac09b4e3e903877c849ffef41308791cbd069ab3873d3c2\n",
            "  Stored in directory: /root/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\n",
            "Successfully built absl-py gast\n",
            "Installing collected packages: numpy, absl-py, tensorflow-estimator, tensorboard, scipy, keras-applications, gast, tensorflow-probability, tensorflow-gpu, tensorflow\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.6\n",
            "    Uninstalling numpy-1.21.6:\n",
            "      Successfully uninstalled numpy-1.21.6\n",
            "  Attempting uninstall: absl-py\n",
            "    Found existing installation: absl-py 1.2.0\n",
            "    Uninstalling absl-py-1.2.0:\n",
            "      Successfully uninstalled absl-py-1.2.0\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.8.0\n",
            "    Uninstalling tensorflow-estimator-2.8.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.8.0\n",
            "    Uninstalling tensorboard-2.8.0:\n",
            "      Successfully uninstalled tensorboard-2.8.0\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.7.3\n",
            "    Uninstalling scipy-1.7.3:\n",
            "      Successfully uninstalled scipy-1.7.3\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.3\n",
            "    Uninstalling gast-0.5.3:\n",
            "      Successfully uninstalled gast-0.5.3\n",
            "  Attempting uninstall: tensorflow-probability\n",
            "    Found existing installation: tensorflow-probability 0.16.0\n",
            "    Uninstalling tensorflow-probability-0.16.0:\n",
            "      Successfully uninstalled tensorflow-probability-0.16.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.8.2+zzzcolab20220719082949\n",
            "    Uninstalling tensorflow-2.8.2+zzzcolab20220719082949:\n",
            "      Successfully uninstalled tensorflow-2.8.2+zzzcolab20220719082949\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "xarray 0.20.2 requires numpy>=1.18, but you have numpy 1.16.4 which is incompatible.\n",
            "xarray-einstats 0.2.2 requires numpy>=1.21, but you have numpy 1.16.4 which is incompatible.\n",
            "tensorflow-metadata 1.9.0 requires absl-py<2.0.0,>=0.9, but you have absl-py 0.7.0 which is incompatible.\n",
            "tables 3.7.0 requires numpy>=1.19.0, but you have numpy 1.16.4 which is incompatible.\n",
            "scikit-image 0.18.3 requires numpy>=1.16.5, but you have numpy 1.16.4 which is incompatible.\n",
            "resampy 0.3.1 requires numpy>=1.17, but you have numpy 1.16.4 which is incompatible.\n",
            "pywavelets 1.3.0 requires numpy>=1.17.3, but you have numpy 1.16.4 which is incompatible.\n",
            "pymc3 3.11.5 requires scipy<1.8.0,>=1.7.3, but you have scipy 1.2.0 which is incompatible.\n",
            "pyerfa 2.0.0.1 requires numpy>=1.17, but you have numpy 1.16.4 which is incompatible.\n",
            "pyarrow 6.0.1 requires numpy>=1.16.6, but you have numpy 1.16.4 which is incompatible.\n",
            "pandas 1.3.5 requires numpy>=1.17.3; platform_machine != \"aarch64\" and platform_machine != \"arm64\" and python_version < \"3.10\", but you have numpy 1.16.4 which is incompatible.\n",
            "kapre 0.3.7 requires numpy>=1.18.5, but you have numpy 1.16.4 which is incompatible.\n",
            "kapre 0.3.7 requires tensorflow>=2.0.0, but you have tensorflow 1.15.0 which is incompatible.\n",
            "jaxlib 0.3.14+cuda11.cudnn805 requires numpy>=1.19, but you have numpy 1.16.4 which is incompatible.\n",
            "jaxlib 0.3.14+cuda11.cudnn805 requires scipy>=1.5, but you have scipy 1.2.0 which is incompatible.\n",
            "jax 0.3.14 requires numpy>=1.19, but you have numpy 1.16.4 which is incompatible.\n",
            "jax 0.3.14 requires scipy>=1.5, but you have scipy 1.2.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "cupy-cuda111 9.4.0 requires numpy<1.24,>=1.17, but you have numpy 1.16.4 which is incompatible.\n",
            "cmdstanpy 1.0.4 requires numpy>=1.21, but you have numpy 1.16.4 which is incompatible.\n",
            "astropy 4.3.1 requires numpy>=1.17, but you have numpy 1.16.4 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed absl-py-0.7.0 gast-0.2.2 keras-applications-1.0.8 numpy-1.16.4 scipy-1.2.0 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1 tensorflow-gpu-1.15.0 tensorflow-probability-0.7.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reprodice hmnist\n",
        "#!data/load_hmnist.sh\n",
        "!python train.py --model_type gp-vae --data_type hmnist --exp_name reproduce_hmnist --seed 111 --testing --banded_covar --latent_dim 256 --encoder_sizes=256,256 --decoder_sizes=256,256,256 --window_size 3 --sigma 1 --length_scale 2 --beta 0.8 --num_epochs 20  --train_class_number 500\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VegyQpEW9ZQT",
        "outputId": "6fa8daf2-1537-4a70-ca22-9793b8e797c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing:  True \t Seed: 111\n",
            "Full exp name:  220731_reproduce_hmnist\n",
            "tcmalloc: large alloc 1881604096 bytes == 0x56b2000 @  0x7f823494c1e7 0x7f82323d5cf1 0x7f823243a7c8 0x7f82323d94f1 0x5947d6 0x548cc1 0x5127f1 0x549576 0x593fce 0x548ae9 0x5127f1 0x4bc98a 0x533274 0x4d3969 0x512147 0x549e0e 0x593fce 0x5118f8 0x593dd7 0x5118f8 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x604173 0x5f5506 0x5f8c6c 0x5f9206 0x64faf2 0x64fc4e\n",
            "tcmalloc: large alloc 1881604096 bytes == 0x759d4000 @  0x7f823494c1e7 0x7f82323d5cf1 0x7f823243a7c8 0x7f82323d94f1 0x5947d6 0x548cc1 0x5127f1 0x549576 0x593fce 0x548ae9 0x5127f1 0x4bc98a 0x533274 0x4d3969 0x512147 0x549e0e 0x593fce 0x5118f8 0x593dd7 0x5118f8 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x604173 0x5f5506 0x5f8c6c 0x5f9206 0x64faf2 0x64fc4e\n",
            "tcmalloc: large alloc 1881604096 bytes == 0xe5c44000 @  0x7f823494c1e7 0x7f82323d5cf1 0x7f823243a7c8 0x7f82323d94f1 0x5947d6 0x548cc1 0x5127f1 0x549576 0x593fce 0x548ae9 0x5127f1 0x4bc98a 0x533274 0x4d3969 0x512147 0x549e0e 0x593fce 0x5118f8 0x593dd7 0x5118f8 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x604173 0x5f5506 0x5f8c6c 0x5f9206 0x64faf2 0x64fc4e\n",
            "5000\n",
            "(5000, 10, 784)\n",
            "2022-07-31 12:10:33.522398: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2022-07-31 12:10:33.553448: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-07-31 12:10:33.554099: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\n",
            "pciBusID: 0000:00:04.0\n",
            "2022-07-31 12:10:33.554425: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2022-07-31 12:10:33.555860: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2022-07-31 12:10:33.557035: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2022-07-31 12:10:33.557361: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2022-07-31 12:10:33.558825: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2022-07-31 12:10:33.559777: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2022-07-31 12:10:33.562955: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2022-07-31 12:10:33.563073: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-07-31 12:10:33.563773: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-07-31 12:10:33.564383: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2022-07-31 12:10:33.564757: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
            "2022-07-31 12:10:33.569191: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000170000 Hz\n",
            "2022-07-31 12:10:33.579132: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x161ea00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2022-07-31 12:10:33.579167: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2022-07-31 12:10:33.709280: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-07-31 12:10:33.713883: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x161e840 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2022-07-31 12:10:33.713945: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-16GB, Compute Capability 7.0\n",
            "2022-07-31 12:10:33.714145: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-07-31 12:10:33.714820: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\n",
            "pciBusID: 0000:00:04.0\n",
            "2022-07-31 12:10:33.714883: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2022-07-31 12:10:33.714901: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2022-07-31 12:10:33.714914: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2022-07-31 12:10:33.714928: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2022-07-31 12:10:33.714943: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2022-07-31 12:10:33.714957: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2022-07-31 12:10:33.714978: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2022-07-31 12:10:33.715043: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-07-31 12:10:33.715726: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-07-31 12:10:33.716299: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2022-07-31 12:10:33.716360: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2022-07-31 12:10:33.717479: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2022-07-31 12:10:33.717508: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2022-07-31 12:10:33.717515: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2022-07-31 12:10:33.717619: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-07-31 12:10:33.718213: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-07-31 12:10:33.718807: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2022-07-31 12:10:33.718846: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15060 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0)\n",
            "W0731 12:10:34.830837 140197209032576 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/data/util/random_seed.py:58: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Using CNN preprocessor\n",
            "2022-07-31 12:10:35.239201: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-07-31 12:10:35.239866: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\n",
            "pciBusID: 0000:00:04.0\n",
            "2022-07-31 12:10:35.239940: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2022-07-31 12:10:35.239958: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2022-07-31 12:10:35.239974: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2022-07-31 12:10:35.239989: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2022-07-31 12:10:35.240001: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2022-07-31 12:10:35.240016: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2022-07-31 12:10:35.240033: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2022-07-31 12:10:35.240100: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-07-31 12:10:35.240678: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-07-31 12:10:35.241176: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2022-07-31 12:10:35.241210: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2022-07-31 12:10:35.241226: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2022-07-31 12:10:35.241232: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2022-07-31 12:10:35.241301: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-07-31 12:10:35.241887: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-07-31 12:10:35.242424: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/device:GPU:0 with 15060 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0)\n",
            "GPU support:  True\n",
            "Training...\n",
            "2022-07-31 12:10:35.249235: I tensorflow/core/kernels/cuda_solvers.cc:159] Creating CudaSolver handles for stream 0x18791a78\n",
            "2022-07-31 12:10:35.249302: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2022-07-31 12:10:35.656703: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2022-07-31 12:10:35.891442: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2022-07-31 12:10:37.118609: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              multiple                  602368    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                multiple                  65792     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              multiple                  197376    \n",
            "=================================================================\n",
            "Total params: 865,536\n",
            "Trainable params: 865,536\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Encoder:  None\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_2 (Dense)              multiple                  65792     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              multiple                  65792     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              multiple                  65792     \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              multiple                  201488    \n",
            "=================================================================\n",
            "Total params: 398,864\n",
            "Trainable params: 398,864\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Decoder:  None\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              multiple                  2560      \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            multiple                  2305      \n",
            "=================================================================\n",
            "Total params: 4,865\n",
            "Trainable params: 4,865\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Preprocessor:  None\n",
            "W0731 12:10:37.202393 140197209032576 lazy_loader.py:50] \n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "================================================\n",
            "Learning rate: 0.001 | Global gradient norm: 508.95\n",
            "Step 0) Time = 1.319768\n",
            "Train loss = 7974.065 | NLL = 2908.426 | KL = 6332.050\n",
            "Validation loss = 8007.656 | NLL = 2939.461 | KL = 6335.244\n",
            "================================================\n",
            "Learning rate: 0.001 | Global gradient norm: 180.52\n",
            "Step 78) Time = 42.847319\n",
            "Train loss = 1590.703 | NLL = 558.863 | KL = 1289.800\n",
            "Validation loss = 1634.850 | NLL = 603.291 | KL = 1289.449\n",
            "================================================\n",
            "Learning rate: 0.001 | Global gradient norm: 522.74\n",
            "Step 156) Time = 43.773015\n",
            "Train loss = 1652.205 | NLL = 630.462 | KL = 1277.178\n",
            "Validation loss = 1607.955 | NLL = 585.933 | KL = 1277.527\n",
            "================================================\n",
            "Learning rate: 0.001 | Global gradient norm: 894.51\n",
            "Step 234) Time = 43.651922\n",
            "Train loss = 1617.242 | NLL = 598.254 | KL = 1273.735\n",
            "Validation loss = 1583.827 | NLL = 564.392 | KL = 1274.293\n",
            "================================================\n",
            "Learning rate: 0.001 | Global gradient norm: 1560.03\n",
            "Step 312) Time = 44.238412\n",
            "Train loss = 1597.325 | NLL = 575.367 | KL = 1277.448\n",
            "Validation loss = 1585.939 | NLL = 564.296 | KL = 1277.053\n",
            "================================================\n",
            "Learning rate: 0.001 | Global gradient norm: 405.78\n",
            "Step 390) Time = 43.521111\n",
            "Train loss = 1575.693 | NLL = 551.406 | KL = 1280.359\n",
            "Validation loss = 1524.063 | NLL = 500.503 | KL = 1279.451\n",
            "================================================\n",
            "Learning rate: 0.001 | Global gradient norm: 1336.55\n",
            "Step 468) Time = 43.350875\n",
            "Train loss = 1545.479 | NLL = 519.112 | KL = 1282.959\n",
            "Validation loss = 1511.207 | NLL = 486.239 | KL = 1281.210\n",
            "================================================\n",
            "Learning rate: 0.001 | Global gradient norm: 1870.39\n",
            "Step 546) Time = 43.401133\n",
            "Train loss = 1518.589 | NLL = 487.813 | KL = 1288.469\n",
            "Validation loss = 1511.979 | NLL = 481.970 | KL = 1287.511\n",
            "================================================\n",
            "Learning rate: 0.001 | Global gradient norm: 762.88\n",
            "Step 624) Time = 44.210339\n",
            "Train loss = 1518.468 | NLL = 483.141 | KL = 1294.158\n",
            "Validation loss = 1496.124 | NLL = 464.385 | KL = 1289.674\n",
            "================================================\n",
            "Learning rate: 0.001 | Global gradient norm: 1209.50\n",
            "Step 702) Time = 43.899347\n",
            "Train loss = 1493.344 | NLL = 457.533 | KL = 1294.764\n",
            "Validation loss = 1481.610 | NLL = 446.451 | KL = 1293.949\n",
            "================================================\n",
            "Learning rate: 0.001 | Global gradient norm: 1267.39\n",
            "Step 780) Time = 41.531062\n",
            "Train loss = 1457.360 | NLL = 421.788 | KL = 1294.464\n",
            "Validation loss = 1439.088 | NLL = 402.839 | KL = 1295.311\n",
            "================================================\n",
            "Learning rate: 0.001 | Global gradient norm: 857.49\n",
            "Step 858) Time = 40.618431\n",
            "Train loss = 1450.244 | NLL = 412.700 | KL = 1296.930\n",
            "Validation loss = 1446.014 | NLL = 407.401 | KL = 1298.266\n",
            "================================================\n",
            "Learning rate: 0.001 | Global gradient norm: 1050.32\n",
            "Step 936) Time = 41.254001\n",
            "Train loss = 1466.664 | NLL = 427.717 | KL = 1298.683\n",
            "Validation loss = 1436.016 | NLL = 397.296 | KL = 1298.400\n",
            "================================================\n",
            "Learning rate: 0.001 | Global gradient norm: 1163.46\n",
            "Step 1014) Time = 40.000653\n",
            "Train loss = 1432.906 | NLL = 390.302 | KL = 1303.256\n",
            "Validation loss = 1429.445 | NLL = 387.752 | KL = 1302.117\n",
            "================================================\n",
            "Learning rate: 0.001 | Global gradient norm: 2604.39\n",
            "Step 1092) Time = 43.254154\n",
            "Train loss = 1448.493 | NLL = 408.102 | KL = 1300.489\n",
            "Validation loss = 1416.650 | NLL = 376.907 | KL = 1299.680\n",
            "================================================\n",
            "Learning rate: 0.001 | Global gradient norm: 937.11\n",
            "Step 1170) Time = 43.386822\n",
            "Train loss = 1438.687 | NLL = 395.468 | KL = 1304.024\n",
            "Validation loss = 1402.922 | NLL = 361.233 | KL = 1302.111\n",
            "================================================\n",
            "Learning rate: 0.001 | Global gradient norm: 2093.40\n",
            "Step 1248) Time = 42.651827\n",
            "Train loss = 1404.748 | NLL = 360.009 | KL = 1305.924\n",
            "Validation loss = 1414.149 | NLL = 371.175 | KL = 1303.716\n",
            "================================================\n",
            "Learning rate: 0.001 | Global gradient norm: 455.49\n",
            "Step 1326) Time = 41.354795\n",
            "Train loss = 1419.586 | NLL = 375.350 | KL = 1305.295\n",
            "Validation loss = 1405.559 | NLL = 362.653 | KL = 1303.633\n",
            "================================================\n",
            "Learning rate: 0.001 | Global gradient norm: 358.07\n",
            "Step 1404) Time = 40.986923\n",
            "Train loss = 1424.827 | NLL = 378.865 | KL = 1307.453\n",
            "Validation loss = 1402.878 | NLL = 358.018 | KL = 1306.074\n",
            "================================================\n",
            "Learning rate: 0.001 | Global gradient norm: 970.16\n",
            "Step 1482) Time = 40.807308\n",
            "Train loss = 1375.323 | NLL = 327.825 | KL = 1309.373\n",
            "Validation loss = 1384.462 | NLL = 339.417 | KL = 1306.307\n",
            "================================================\n",
            "Learning rate: 0.001 | Global gradient norm: 559.04\n",
            "Step 1560) Time = 41.585268\n",
            "Train loss = 1387.740 | NLL = 340.798 | KL = 1308.678\n",
            "Validation loss = 1390.693 | NLL = 345.770 | KL = 1306.154\n",
            "Evaluation...\n",
            "NLL miss: 0.3639\n",
            "MSE miss: 0.1437\n",
            "AUROC: 0.9595\n",
            "AUPRC: 0.8051\n",
            "Training finished.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy trained models back to drive\n",
        "!cp -R models/* $ROOT_DIR/models\n",
        "!ls -la $ROOT_DIR/models"
      ],
      "metadata": {
        "id": "Se5Ggzi2Q4NS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8de3d98b-cf7e-4cf8-8c1f-bb696fee63ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 4\n",
            "drwx------ 2 root root 4096 Jul 31 12:38 220731_reproduce_hmnist\n",
            "-rw------- 1 root root    0 Jul 14 11:18 .gitkeep\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Reproduce Sprites\n",
        "!data/load_sprites.sh\n",
        "!python train.py --model_type gp-vae --data_type sprites --exp_name reproduce_sprites --seed $RANDOM --testing --banded_covar --latent_dim 256 --encoder_sizes=32,256,256 --decoder_sizes=256,256,256 --window_size 3 --sigma 1 --length_scale 2 --beta 0.1 --num_epochs 20"
      ],
      "metadata": {
        "id": "AxQF2TDFwkgd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy trained models back to drive\n",
        "!cp -R models/* $ROOT_DIR/models\n",
        "!ls -la $ROOT_DIR/models"
      ],
      "metadata": {
        "id": "9CjYpsMFy-gt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Reproduce Physionet\n",
        "!data/load_physionet.sh\n",
        "!python train.py --model_type gp-vae --data_type physionet --exp_name reproduce_physionet --seed $RANDOM --testing --banded_covar --latent_dim 35 --encoder_sizes=128,128 --decoder_sizes=256,256 --window_size 24 --sigma 1.005 --length_scale 7 --beta 0.2 --num_epochs 40"
      ],
      "metadata": {
        "id": "elZKZRojy_eE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy trained models back to drive\n",
        "!cp -R models/* $ROOT_DIR/models\n",
        "!ls -la $ROOT_DIR/models"
      ],
      "metadata": {
        "id": "eyB_Izp-y_mA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}